{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 11880,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016835016835016835,
      "grad_norm": 3.520048141479492,
      "learning_rate": 4.972222222222223e-05,
      "loss": 0.4112,
      "step": 200
    },
    {
      "epoch": 0.03367003367003367,
      "grad_norm": 2.696779489517212,
      "learning_rate": 4.944163860830528e-05,
      "loss": 0.3436,
      "step": 400
    },
    {
      "epoch": 0.050505050505050504,
      "grad_norm": 1.8330892324447632,
      "learning_rate": 4.916105499438833e-05,
      "loss": 0.324,
      "step": 600
    },
    {
      "epoch": 0.06734006734006734,
      "grad_norm": 2.400930643081665,
      "learning_rate": 4.8880471380471385e-05,
      "loss": 0.3042,
      "step": 800
    },
    {
      "epoch": 0.08417508417508418,
      "grad_norm": 9.420417785644531,
      "learning_rate": 4.8599887766554436e-05,
      "loss": 0.3054,
      "step": 1000
    },
    {
      "epoch": 0.10101010101010101,
      "grad_norm": 2.366161346435547,
      "learning_rate": 4.831930415263749e-05,
      "loss": 0.292,
      "step": 1200
    },
    {
      "epoch": 0.11784511784511785,
      "grad_norm": 2.7628226280212402,
      "learning_rate": 4.8038720538720536e-05,
      "loss": 0.3115,
      "step": 1400
    },
    {
      "epoch": 0.13468013468013468,
      "grad_norm": 7.399234294891357,
      "learning_rate": 4.7758136924803594e-05,
      "loss": 0.3066,
      "step": 1600
    },
    {
      "epoch": 0.15151515151515152,
      "grad_norm": 2.1039657592773438,
      "learning_rate": 4.7477553310886644e-05,
      "loss": 0.2847,
      "step": 1800
    },
    {
      "epoch": 0.16835016835016836,
      "grad_norm": 2.218571186065674,
      "learning_rate": 4.71969696969697e-05,
      "loss": 0.2673,
      "step": 2000
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 3.5632951259613037,
      "learning_rate": 4.691638608305275e-05,
      "loss": 0.2839,
      "step": 2200
    },
    {
      "epoch": 0.20202020202020202,
      "grad_norm": 7.730218410491943,
      "learning_rate": 4.66358024691358e-05,
      "loss": 0.2691,
      "step": 2400
    },
    {
      "epoch": 0.21885521885521886,
      "grad_norm": 2.720079183578491,
      "learning_rate": 4.635521885521886e-05,
      "loss": 0.2734,
      "step": 2600
    },
    {
      "epoch": 0.2356902356902357,
      "grad_norm": 3.1955599784851074,
      "learning_rate": 4.607463524130191e-05,
      "loss": 0.2662,
      "step": 2800
    },
    {
      "epoch": 0.25252525252525254,
      "grad_norm": 2.1058366298675537,
      "learning_rate": 4.5794051627384966e-05,
      "loss": 0.2663,
      "step": 3000
    },
    {
      "epoch": 0.26936026936026936,
      "grad_norm": 1.101463794708252,
      "learning_rate": 4.551346801346802e-05,
      "loss": 0.276,
      "step": 3200
    },
    {
      "epoch": 0.28619528619528617,
      "grad_norm": 2.6533820629119873,
      "learning_rate": 4.523288439955107e-05,
      "loss": 0.2865,
      "step": 3400
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 3.6868789196014404,
      "learning_rate": 4.4952300785634124e-05,
      "loss": 0.2671,
      "step": 3600
    },
    {
      "epoch": 0.31986531986531985,
      "grad_norm": 5.6773505210876465,
      "learning_rate": 4.4671717171717174e-05,
      "loss": 0.2734,
      "step": 3800
    },
    {
      "epoch": 0.3367003367003367,
      "grad_norm": 2.0585060119628906,
      "learning_rate": 4.4391133557800225e-05,
      "loss": 0.2707,
      "step": 4000
    },
    {
      "epoch": 0.35353535353535354,
      "grad_norm": 3.126016139984131,
      "learning_rate": 4.4110549943883275e-05,
      "loss": 0.2474,
      "step": 4200
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 3.9228930473327637,
      "learning_rate": 4.382996632996633e-05,
      "loss": 0.2626,
      "step": 4400
    },
    {
      "epoch": 0.3872053872053872,
      "grad_norm": 0.9169366359710693,
      "learning_rate": 4.354938271604939e-05,
      "loss": 0.2685,
      "step": 4600
    },
    {
      "epoch": 0.40404040404040403,
      "grad_norm": 2.3747451305389404,
      "learning_rate": 4.326879910213244e-05,
      "loss": 0.2694,
      "step": 4800
    },
    {
      "epoch": 0.4208754208754209,
      "grad_norm": 1.8194974660873413,
      "learning_rate": 4.298821548821549e-05,
      "loss": 0.2613,
      "step": 5000
    },
    {
      "epoch": 0.4377104377104377,
      "grad_norm": 3.123154401779175,
      "learning_rate": 4.270763187429854e-05,
      "loss": 0.2694,
      "step": 5200
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.7264204025268555,
      "learning_rate": 4.24270482603816e-05,
      "loss": 0.2314,
      "step": 5400
    },
    {
      "epoch": 0.4713804713804714,
      "grad_norm": 2.3297173976898193,
      "learning_rate": 4.214646464646465e-05,
      "loss": 0.2557,
      "step": 5600
    },
    {
      "epoch": 0.4882154882154882,
      "grad_norm": 2.5795438289642334,
      "learning_rate": 4.186728395061729e-05,
      "loss": 0.2246,
      "step": 5800
    },
    {
      "epoch": 0.5050505050505051,
      "grad_norm": 3.7536072731018066,
      "learning_rate": 4.158670033670034e-05,
      "loss": 0.2407,
      "step": 6000
    },
    {
      "epoch": 0.5218855218855218,
      "grad_norm": 5.786057949066162,
      "learning_rate": 4.130611672278339e-05,
      "loss": 0.2429,
      "step": 6200
    },
    {
      "epoch": 0.5387205387205387,
      "grad_norm": 4.085837364196777,
      "learning_rate": 4.102553310886644e-05,
      "loss": 0.2479,
      "step": 6400
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 1.946946620941162,
      "learning_rate": 4.07449494949495e-05,
      "loss": 0.2374,
      "step": 6600
    },
    {
      "epoch": 0.5723905723905723,
      "grad_norm": 2.9785821437835693,
      "learning_rate": 4.0464365881032554e-05,
      "loss": 0.2467,
      "step": 6800
    },
    {
      "epoch": 0.5892255892255892,
      "grad_norm": 5.283841133117676,
      "learning_rate": 4.0183782267115605e-05,
      "loss": 0.2222,
      "step": 7000
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 3.460195541381836,
      "learning_rate": 3.9903198653198655e-05,
      "loss": 0.242,
      "step": 7200
    },
    {
      "epoch": 0.622895622895623,
      "grad_norm": 5.013827800750732,
      "learning_rate": 3.9622615039281705e-05,
      "loss": 0.2363,
      "step": 7400
    },
    {
      "epoch": 0.6397306397306397,
      "grad_norm": 0.9473376870155334,
      "learning_rate": 3.934203142536476e-05,
      "loss": 0.2226,
      "step": 7600
    },
    {
      "epoch": 0.6565656565656566,
      "grad_norm": 2.787233591079712,
      "learning_rate": 3.906144781144781e-05,
      "loss": 0.2338,
      "step": 7800
    },
    {
      "epoch": 0.6734006734006734,
      "grad_norm": 4.027620792388916,
      "learning_rate": 3.878086419753086e-05,
      "loss": 0.2311,
      "step": 8000
    },
    {
      "epoch": 0.6902356902356902,
      "grad_norm": 2.972388744354248,
      "learning_rate": 3.850028058361392e-05,
      "loss": 0.2306,
      "step": 8200
    },
    {
      "epoch": 0.7070707070707071,
      "grad_norm": 1.3905349969863892,
      "learning_rate": 3.8221099887766555e-05,
      "loss": 0.245,
      "step": 8400
    },
    {
      "epoch": 0.7239057239057239,
      "grad_norm": 0.9558162689208984,
      "learning_rate": 3.7940516273849605e-05,
      "loss": 0.2477,
      "step": 8600
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 2.7707419395446777,
      "learning_rate": 3.765993265993266e-05,
      "loss": 0.2576,
      "step": 8800
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 0.32943031191825867,
      "learning_rate": 3.7380751964085296e-05,
      "loss": 0.2352,
      "step": 9000
    },
    {
      "epoch": 0.7744107744107744,
      "grad_norm": 2.176053762435913,
      "learning_rate": 3.7100168350168354e-05,
      "loss": 0.2231,
      "step": 9200
    },
    {
      "epoch": 0.7912457912457912,
      "grad_norm": 7.524020671844482,
      "learning_rate": 3.6819584736251404e-05,
      "loss": 0.2181,
      "step": 9400
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 1.7738755941390991,
      "learning_rate": 3.653900112233446e-05,
      "loss": 0.2133,
      "step": 9600
    },
    {
      "epoch": 0.8249158249158249,
      "grad_norm": 1.9196853637695312,
      "learning_rate": 3.625841750841751e-05,
      "loss": 0.227,
      "step": 9800
    },
    {
      "epoch": 0.8417508417508418,
      "grad_norm": 5.024656295776367,
      "learning_rate": 3.597783389450056e-05,
      "loss": 0.212,
      "step": 10000
    },
    {
      "epoch": 0.8585858585858586,
      "grad_norm": 5.356096267700195,
      "learning_rate": 3.569725028058362e-05,
      "loss": 0.2264,
      "step": 10200
    },
    {
      "epoch": 0.8754208754208754,
      "grad_norm": 3.3534207344055176,
      "learning_rate": 3.541666666666667e-05,
      "loss": 0.2199,
      "step": 10400
    },
    {
      "epoch": 0.8922558922558923,
      "grad_norm": 7.703488826751709,
      "learning_rate": 3.513608305274972e-05,
      "loss": 0.2045,
      "step": 10600
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 3.7369906902313232,
      "learning_rate": 3.485549943883277e-05,
      "loss": 0.2141,
      "step": 10800
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 2.8575222492218018,
      "learning_rate": 3.457491582491583e-05,
      "loss": 0.2086,
      "step": 11000
    },
    {
      "epoch": 0.9427609427609428,
      "grad_norm": 3.5251076221466064,
      "learning_rate": 3.429433221099888e-05,
      "loss": 0.2185,
      "step": 11200
    },
    {
      "epoch": 0.9595959595959596,
      "grad_norm": 3.853459358215332,
      "learning_rate": 3.4013748597081934e-05,
      "loss": 0.2238,
      "step": 11400
    },
    {
      "epoch": 0.9764309764309764,
      "grad_norm": 8.127949714660645,
      "learning_rate": 3.3733164983164985e-05,
      "loss": 0.2193,
      "step": 11600
    },
    {
      "epoch": 0.9932659932659933,
      "grad_norm": 5.363415241241455,
      "learning_rate": 3.3452581369248035e-05,
      "loss": 0.1995,
      "step": 11800
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.22413210570812225,
      "eval_runtime": 40.8416,
      "eval_samples_per_second": 1163.447,
      "eval_steps_per_second": 72.72,
      "step": 11880
    }
  ],
  "logging_steps": 200,
  "max_steps": 35640,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6294453381937152.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}

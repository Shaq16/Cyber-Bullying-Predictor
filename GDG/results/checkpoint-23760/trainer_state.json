{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 23760,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016835016835016835,
      "grad_norm": 3.520048141479492,
      "learning_rate": 4.972222222222223e-05,
      "loss": 0.4112,
      "step": 200
    },
    {
      "epoch": 0.03367003367003367,
      "grad_norm": 2.696779489517212,
      "learning_rate": 4.944163860830528e-05,
      "loss": 0.3436,
      "step": 400
    },
    {
      "epoch": 0.050505050505050504,
      "grad_norm": 1.8330892324447632,
      "learning_rate": 4.916105499438833e-05,
      "loss": 0.324,
      "step": 600
    },
    {
      "epoch": 0.06734006734006734,
      "grad_norm": 2.400930643081665,
      "learning_rate": 4.8880471380471385e-05,
      "loss": 0.3042,
      "step": 800
    },
    {
      "epoch": 0.08417508417508418,
      "grad_norm": 9.420417785644531,
      "learning_rate": 4.8599887766554436e-05,
      "loss": 0.3054,
      "step": 1000
    },
    {
      "epoch": 0.10101010101010101,
      "grad_norm": 2.366161346435547,
      "learning_rate": 4.831930415263749e-05,
      "loss": 0.292,
      "step": 1200
    },
    {
      "epoch": 0.11784511784511785,
      "grad_norm": 2.7628226280212402,
      "learning_rate": 4.8038720538720536e-05,
      "loss": 0.3115,
      "step": 1400
    },
    {
      "epoch": 0.13468013468013468,
      "grad_norm": 7.399234294891357,
      "learning_rate": 4.7758136924803594e-05,
      "loss": 0.3066,
      "step": 1600
    },
    {
      "epoch": 0.15151515151515152,
      "grad_norm": 2.1039657592773438,
      "learning_rate": 4.7477553310886644e-05,
      "loss": 0.2847,
      "step": 1800
    },
    {
      "epoch": 0.16835016835016836,
      "grad_norm": 2.218571186065674,
      "learning_rate": 4.71969696969697e-05,
      "loss": 0.2673,
      "step": 2000
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 3.5632951259613037,
      "learning_rate": 4.691638608305275e-05,
      "loss": 0.2839,
      "step": 2200
    },
    {
      "epoch": 0.20202020202020202,
      "grad_norm": 7.730218410491943,
      "learning_rate": 4.66358024691358e-05,
      "loss": 0.2691,
      "step": 2400
    },
    {
      "epoch": 0.21885521885521886,
      "grad_norm": 2.720079183578491,
      "learning_rate": 4.635521885521886e-05,
      "loss": 0.2734,
      "step": 2600
    },
    {
      "epoch": 0.2356902356902357,
      "grad_norm": 3.1955599784851074,
      "learning_rate": 4.607463524130191e-05,
      "loss": 0.2662,
      "step": 2800
    },
    {
      "epoch": 0.25252525252525254,
      "grad_norm": 2.1058366298675537,
      "learning_rate": 4.5794051627384966e-05,
      "loss": 0.2663,
      "step": 3000
    },
    {
      "epoch": 0.26936026936026936,
      "grad_norm": 1.101463794708252,
      "learning_rate": 4.551346801346802e-05,
      "loss": 0.276,
      "step": 3200
    },
    {
      "epoch": 0.28619528619528617,
      "grad_norm": 2.6533820629119873,
      "learning_rate": 4.523288439955107e-05,
      "loss": 0.2865,
      "step": 3400
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 3.6868789196014404,
      "learning_rate": 4.4952300785634124e-05,
      "loss": 0.2671,
      "step": 3600
    },
    {
      "epoch": 0.31986531986531985,
      "grad_norm": 5.6773505210876465,
      "learning_rate": 4.4671717171717174e-05,
      "loss": 0.2734,
      "step": 3800
    },
    {
      "epoch": 0.3367003367003367,
      "grad_norm": 2.0585060119628906,
      "learning_rate": 4.4391133557800225e-05,
      "loss": 0.2707,
      "step": 4000
    },
    {
      "epoch": 0.35353535353535354,
      "grad_norm": 3.126016139984131,
      "learning_rate": 4.4110549943883275e-05,
      "loss": 0.2474,
      "step": 4200
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 3.9228930473327637,
      "learning_rate": 4.382996632996633e-05,
      "loss": 0.2626,
      "step": 4400
    },
    {
      "epoch": 0.3872053872053872,
      "grad_norm": 0.9169366359710693,
      "learning_rate": 4.354938271604939e-05,
      "loss": 0.2685,
      "step": 4600
    },
    {
      "epoch": 0.40404040404040403,
      "grad_norm": 2.3747451305389404,
      "learning_rate": 4.326879910213244e-05,
      "loss": 0.2694,
      "step": 4800
    },
    {
      "epoch": 0.4208754208754209,
      "grad_norm": 1.8194974660873413,
      "learning_rate": 4.298821548821549e-05,
      "loss": 0.2613,
      "step": 5000
    },
    {
      "epoch": 0.4377104377104377,
      "grad_norm": 3.123154401779175,
      "learning_rate": 4.270763187429854e-05,
      "loss": 0.2694,
      "step": 5200
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.7264204025268555,
      "learning_rate": 4.24270482603816e-05,
      "loss": 0.2314,
      "step": 5400
    },
    {
      "epoch": 0.4713804713804714,
      "grad_norm": 2.3297173976898193,
      "learning_rate": 4.214646464646465e-05,
      "loss": 0.2557,
      "step": 5600
    },
    {
      "epoch": 0.4882154882154882,
      "grad_norm": 2.5795438289642334,
      "learning_rate": 4.186728395061729e-05,
      "loss": 0.2246,
      "step": 5800
    },
    {
      "epoch": 0.5050505050505051,
      "grad_norm": 3.7536072731018066,
      "learning_rate": 4.158670033670034e-05,
      "loss": 0.2407,
      "step": 6000
    },
    {
      "epoch": 0.5218855218855218,
      "grad_norm": 5.786057949066162,
      "learning_rate": 4.130611672278339e-05,
      "loss": 0.2429,
      "step": 6200
    },
    {
      "epoch": 0.5387205387205387,
      "grad_norm": 4.085837364196777,
      "learning_rate": 4.102553310886644e-05,
      "loss": 0.2479,
      "step": 6400
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 1.946946620941162,
      "learning_rate": 4.07449494949495e-05,
      "loss": 0.2374,
      "step": 6600
    },
    {
      "epoch": 0.5723905723905723,
      "grad_norm": 2.9785821437835693,
      "learning_rate": 4.0464365881032554e-05,
      "loss": 0.2467,
      "step": 6800
    },
    {
      "epoch": 0.5892255892255892,
      "grad_norm": 5.283841133117676,
      "learning_rate": 4.0183782267115605e-05,
      "loss": 0.2222,
      "step": 7000
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 3.460195541381836,
      "learning_rate": 3.9903198653198655e-05,
      "loss": 0.242,
      "step": 7200
    },
    {
      "epoch": 0.622895622895623,
      "grad_norm": 5.013827800750732,
      "learning_rate": 3.9622615039281705e-05,
      "loss": 0.2363,
      "step": 7400
    },
    {
      "epoch": 0.6397306397306397,
      "grad_norm": 0.9473376870155334,
      "learning_rate": 3.934203142536476e-05,
      "loss": 0.2226,
      "step": 7600
    },
    {
      "epoch": 0.6565656565656566,
      "grad_norm": 2.787233591079712,
      "learning_rate": 3.906144781144781e-05,
      "loss": 0.2338,
      "step": 7800
    },
    {
      "epoch": 0.6734006734006734,
      "grad_norm": 4.027620792388916,
      "learning_rate": 3.878086419753086e-05,
      "loss": 0.2311,
      "step": 8000
    },
    {
      "epoch": 0.6902356902356902,
      "grad_norm": 2.972388744354248,
      "learning_rate": 3.850028058361392e-05,
      "loss": 0.2306,
      "step": 8200
    },
    {
      "epoch": 0.7070707070707071,
      "grad_norm": 1.3905349969863892,
      "learning_rate": 3.8221099887766555e-05,
      "loss": 0.245,
      "step": 8400
    },
    {
      "epoch": 0.7239057239057239,
      "grad_norm": 0.9558162689208984,
      "learning_rate": 3.7940516273849605e-05,
      "loss": 0.2477,
      "step": 8600
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 2.7707419395446777,
      "learning_rate": 3.765993265993266e-05,
      "loss": 0.2576,
      "step": 8800
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 0.32943031191825867,
      "learning_rate": 3.7380751964085296e-05,
      "loss": 0.2352,
      "step": 9000
    },
    {
      "epoch": 0.7744107744107744,
      "grad_norm": 2.176053762435913,
      "learning_rate": 3.7100168350168354e-05,
      "loss": 0.2231,
      "step": 9200
    },
    {
      "epoch": 0.7912457912457912,
      "grad_norm": 7.524020671844482,
      "learning_rate": 3.6819584736251404e-05,
      "loss": 0.2181,
      "step": 9400
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 1.7738755941390991,
      "learning_rate": 3.653900112233446e-05,
      "loss": 0.2133,
      "step": 9600
    },
    {
      "epoch": 0.8249158249158249,
      "grad_norm": 1.9196853637695312,
      "learning_rate": 3.625841750841751e-05,
      "loss": 0.227,
      "step": 9800
    },
    {
      "epoch": 0.8417508417508418,
      "grad_norm": 5.024656295776367,
      "learning_rate": 3.597783389450056e-05,
      "loss": 0.212,
      "step": 10000
    },
    {
      "epoch": 0.8585858585858586,
      "grad_norm": 5.356096267700195,
      "learning_rate": 3.569725028058362e-05,
      "loss": 0.2264,
      "step": 10200
    },
    {
      "epoch": 0.8754208754208754,
      "grad_norm": 3.3534207344055176,
      "learning_rate": 3.541666666666667e-05,
      "loss": 0.2199,
      "step": 10400
    },
    {
      "epoch": 0.8922558922558923,
      "grad_norm": 7.703488826751709,
      "learning_rate": 3.513608305274972e-05,
      "loss": 0.2045,
      "step": 10600
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 3.7369906902313232,
      "learning_rate": 3.485549943883277e-05,
      "loss": 0.2141,
      "step": 10800
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 2.8575222492218018,
      "learning_rate": 3.457491582491583e-05,
      "loss": 0.2086,
      "step": 11000
    },
    {
      "epoch": 0.9427609427609428,
      "grad_norm": 3.5251076221466064,
      "learning_rate": 3.429433221099888e-05,
      "loss": 0.2185,
      "step": 11200
    },
    {
      "epoch": 0.9595959595959596,
      "grad_norm": 3.853459358215332,
      "learning_rate": 3.4013748597081934e-05,
      "loss": 0.2238,
      "step": 11400
    },
    {
      "epoch": 0.9764309764309764,
      "grad_norm": 8.127949714660645,
      "learning_rate": 3.3733164983164985e-05,
      "loss": 0.2193,
      "step": 11600
    },
    {
      "epoch": 0.9932659932659933,
      "grad_norm": 5.363415241241455,
      "learning_rate": 3.3452581369248035e-05,
      "loss": 0.1995,
      "step": 11800
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.22413210570812225,
      "eval_runtime": 40.8416,
      "eval_samples_per_second": 1163.447,
      "eval_steps_per_second": 72.72,
      "step": 11880
    },
    {
      "epoch": 1.0101010101010102,
      "grad_norm": 7.867246150970459,
      "learning_rate": 3.317199775533109e-05,
      "loss": 0.1768,
      "step": 12000
    },
    {
      "epoch": 1.026936026936027,
      "grad_norm": 8.459670066833496,
      "learning_rate": 3.289141414141414e-05,
      "loss": 0.1515,
      "step": 12200
    },
    {
      "epoch": 1.0437710437710437,
      "grad_norm": 4.118003845214844,
      "learning_rate": 3.261083052749719e-05,
      "loss": 0.151,
      "step": 12400
    },
    {
      "epoch": 1.0606060606060606,
      "grad_norm": 0.5313941836357117,
      "learning_rate": 3.233024691358025e-05,
      "loss": 0.1689,
      "step": 12600
    },
    {
      "epoch": 1.0774410774410774,
      "grad_norm": 6.884047031402588,
      "learning_rate": 3.20496632996633e-05,
      "loss": 0.1484,
      "step": 12800
    },
    {
      "epoch": 1.0942760942760943,
      "grad_norm": 7.027196407318115,
      "learning_rate": 3.1770482603815935e-05,
      "loss": 0.1707,
      "step": 13000
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 8.448893547058105,
      "learning_rate": 3.148989898989899e-05,
      "loss": 0.1539,
      "step": 13200
    },
    {
      "epoch": 1.127946127946128,
      "grad_norm": 0.7768488526344299,
      "learning_rate": 3.120931537598204e-05,
      "loss": 0.1568,
      "step": 13400
    },
    {
      "epoch": 1.144781144781145,
      "grad_norm": 3.2092201709747314,
      "learning_rate": 3.0930134680134683e-05,
      "loss": 0.1759,
      "step": 13600
    },
    {
      "epoch": 1.1616161616161615,
      "grad_norm": 4.708727836608887,
      "learning_rate": 3.0649551066217734e-05,
      "loss": 0.1545,
      "step": 13800
    },
    {
      "epoch": 1.1784511784511784,
      "grad_norm": 2.8550212383270264,
      "learning_rate": 3.036896745230079e-05,
      "loss": 0.1645,
      "step": 14000
    },
    {
      "epoch": 1.1952861952861953,
      "grad_norm": 1.4140082597732544,
      "learning_rate": 3.0088383838383838e-05,
      "loss": 0.1431,
      "step": 14200
    },
    {
      "epoch": 1.2121212121212122,
      "grad_norm": 0.458721786737442,
      "learning_rate": 2.980780022446689e-05,
      "loss": 0.1498,
      "step": 14400
    },
    {
      "epoch": 1.228956228956229,
      "grad_norm": 2.9178624153137207,
      "learning_rate": 2.9527216610549945e-05,
      "loss": 0.1553,
      "step": 14600
    },
    {
      "epoch": 1.2457912457912457,
      "grad_norm": 5.086089611053467,
      "learning_rate": 2.9246632996633e-05,
      "loss": 0.1642,
      "step": 14800
    },
    {
      "epoch": 1.2626262626262625,
      "grad_norm": 0.5298435688018799,
      "learning_rate": 2.896604938271605e-05,
      "loss": 0.154,
      "step": 15000
    },
    {
      "epoch": 1.2794612794612794,
      "grad_norm": 2.7525150775909424,
      "learning_rate": 2.8685465768799103e-05,
      "loss": 0.1629,
      "step": 15200
    },
    {
      "epoch": 1.2962962962962963,
      "grad_norm": 5.713521480560303,
      "learning_rate": 2.8404882154882157e-05,
      "loss": 0.1515,
      "step": 15400
    },
    {
      "epoch": 1.3131313131313131,
      "grad_norm": 2.2717514038085938,
      "learning_rate": 2.812429854096521e-05,
      "loss": 0.1609,
      "step": 15600
    },
    {
      "epoch": 1.32996632996633,
      "grad_norm": 6.340275764465332,
      "learning_rate": 2.7843714927048264e-05,
      "loss": 0.1577,
      "step": 15800
    },
    {
      "epoch": 1.3468013468013469,
      "grad_norm": 5.537825584411621,
      "learning_rate": 2.756313131313131e-05,
      "loss": 0.1575,
      "step": 16000
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 5.769209861755371,
      "learning_rate": 2.728254769921437e-05,
      "loss": 0.1644,
      "step": 16200
    },
    {
      "epoch": 1.3804713804713804,
      "grad_norm": 0.6079990267753601,
      "learning_rate": 2.7001964085297422e-05,
      "loss": 0.1516,
      "step": 16400
    },
    {
      "epoch": 1.3973063973063973,
      "grad_norm": 0.39035385847091675,
      "learning_rate": 2.6722783389450057e-05,
      "loss": 0.1555,
      "step": 16600
    },
    {
      "epoch": 1.4141414141414141,
      "grad_norm": 0.48817843198776245,
      "learning_rate": 2.644219977553311e-05,
      "loss": 0.1512,
      "step": 16800
    },
    {
      "epoch": 1.430976430976431,
      "grad_norm": 0.5285249948501587,
      "learning_rate": 2.6161616161616164e-05,
      "loss": 0.1591,
      "step": 17000
    },
    {
      "epoch": 1.4478114478114479,
      "grad_norm": 5.7947001457214355,
      "learning_rate": 2.5881032547699214e-05,
      "loss": 0.1633,
      "step": 17200
    },
    {
      "epoch": 1.4646464646464645,
      "grad_norm": 1.342932105064392,
      "learning_rate": 2.5600448933782268e-05,
      "loss": 0.1595,
      "step": 17400
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 0.8519083261489868,
      "learning_rate": 2.5319865319865322e-05,
      "loss": 0.157,
      "step": 17600
    },
    {
      "epoch": 1.4983164983164983,
      "grad_norm": 5.3107428550720215,
      "learning_rate": 2.5039281705948376e-05,
      "loss": 0.1528,
      "step": 17800
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 1.4348235130310059,
      "learning_rate": 2.4758698092031426e-05,
      "loss": 0.1556,
      "step": 18000
    },
    {
      "epoch": 1.531986531986532,
      "grad_norm": 3.404109239578247,
      "learning_rate": 2.447811447811448e-05,
      "loss": 0.1657,
      "step": 18200
    },
    {
      "epoch": 1.5488215488215489,
      "grad_norm": 6.897884845733643,
      "learning_rate": 2.4197530864197533e-05,
      "loss": 0.1572,
      "step": 18400
    },
    {
      "epoch": 1.5656565656565657,
      "grad_norm": 1.7636278867721558,
      "learning_rate": 2.391835016835017e-05,
      "loss": 0.1365,
      "step": 18600
    },
    {
      "epoch": 1.5824915824915826,
      "grad_norm": 0.432094544172287,
      "learning_rate": 2.363776655443322e-05,
      "loss": 0.1538,
      "step": 18800
    },
    {
      "epoch": 1.5993265993265995,
      "grad_norm": 1.1732593774795532,
      "learning_rate": 2.3357182940516275e-05,
      "loss": 0.1486,
      "step": 19000
    },
    {
      "epoch": 1.6161616161616161,
      "grad_norm": 0.16337211430072784,
      "learning_rate": 2.3076599326599326e-05,
      "loss": 0.1497,
      "step": 19200
    },
    {
      "epoch": 1.632996632996633,
      "grad_norm": 6.924130439758301,
      "learning_rate": 2.279601571268238e-05,
      "loss": 0.1559,
      "step": 19400
    },
    {
      "epoch": 1.6498316498316499,
      "grad_norm": 0.4759446084499359,
      "learning_rate": 2.2515432098765433e-05,
      "loss": 0.1476,
      "step": 19600
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.9820820093154907,
      "learning_rate": 2.2234848484848487e-05,
      "loss": 0.1454,
      "step": 19800
    },
    {
      "epoch": 1.6835016835016834,
      "grad_norm": 20.639434814453125,
      "learning_rate": 2.1954264870931537e-05,
      "loss": 0.1549,
      "step": 20000
    },
    {
      "epoch": 1.7003367003367003,
      "grad_norm": 2.685741901397705,
      "learning_rate": 2.167368125701459e-05,
      "loss": 0.1324,
      "step": 20200
    },
    {
      "epoch": 1.7171717171717171,
      "grad_norm": 9.048433303833008,
      "learning_rate": 2.1393097643097644e-05,
      "loss": 0.1422,
      "step": 20400
    },
    {
      "epoch": 1.734006734006734,
      "grad_norm": 0.21497742831707,
      "learning_rate": 2.1112514029180698e-05,
      "loss": 0.1444,
      "step": 20600
    },
    {
      "epoch": 1.7508417508417509,
      "grad_norm": 16.91347885131836,
      "learning_rate": 2.0831930415263752e-05,
      "loss": 0.1553,
      "step": 20800
    },
    {
      "epoch": 1.7676767676767677,
      "grad_norm": 2.2910242080688477,
      "learning_rate": 2.0551346801346802e-05,
      "loss": 0.1502,
      "step": 21000
    },
    {
      "epoch": 1.7845117845117846,
      "grad_norm": 0.18139155209064484,
      "learning_rate": 2.0270763187429856e-05,
      "loss": 0.1477,
      "step": 21200
    },
    {
      "epoch": 1.8013468013468015,
      "grad_norm": 3.482079029083252,
      "learning_rate": 1.9990179573512906e-05,
      "loss": 0.1687,
      "step": 21400
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 3.6593451499938965,
      "learning_rate": 1.9710998877665544e-05,
      "loss": 0.139,
      "step": 21600
    },
    {
      "epoch": 1.835016835016835,
      "grad_norm": 8.40959644317627,
      "learning_rate": 1.9430415263748598e-05,
      "loss": 0.1425,
      "step": 21800
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 8.000655174255371,
      "learning_rate": 1.914983164983165e-05,
      "loss": 0.147,
      "step": 22000
    },
    {
      "epoch": 1.8686868686868687,
      "grad_norm": 0.22429566085338593,
      "learning_rate": 1.8869248035914702e-05,
      "loss": 0.144,
      "step": 22200
    },
    {
      "epoch": 1.8855218855218854,
      "grad_norm": 0.5088008046150208,
      "learning_rate": 1.8588664421997756e-05,
      "loss": 0.1384,
      "step": 22400
    },
    {
      "epoch": 1.9023569023569022,
      "grad_norm": 2.523719310760498,
      "learning_rate": 1.830808080808081e-05,
      "loss": 0.1584,
      "step": 22600
    },
    {
      "epoch": 1.9191919191919191,
      "grad_norm": 0.23331062495708466,
      "learning_rate": 1.8027497194163863e-05,
      "loss": 0.1429,
      "step": 22800
    },
    {
      "epoch": 1.936026936026936,
      "grad_norm": 4.537326335906982,
      "learning_rate": 1.7746913580246917e-05,
      "loss": 0.156,
      "step": 23000
    },
    {
      "epoch": 1.9528619528619529,
      "grad_norm": 13.340309143066406,
      "learning_rate": 1.7466329966329967e-05,
      "loss": 0.1628,
      "step": 23200
    },
    {
      "epoch": 1.9696969696969697,
      "grad_norm": 11.87214469909668,
      "learning_rate": 1.718574635241302e-05,
      "loss": 0.1452,
      "step": 23400
    },
    {
      "epoch": 1.9865319865319866,
      "grad_norm": 8.352505683898926,
      "learning_rate": 1.690516273849607e-05,
      "loss": 0.1468,
      "step": 23600
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.22271579504013062,
      "eval_runtime": 38.6271,
      "eval_samples_per_second": 1230.146,
      "eval_steps_per_second": 76.889,
      "step": 23760
    }
  ],
  "logging_steps": 200,
  "max_steps": 35640,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2588906763874304e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
